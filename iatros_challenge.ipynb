{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('iatros': conda)",
   "display_name": "Python 3.8.5 64-bit ('iatros': conda)",
   "metadata": {
    "interpreter": {
     "hash": "96d269a9b49747d14c0ac4bff2de003b3d4010f4c68b77dc8330467798d6388d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, parse_qsl, urlsplit\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import json\n",
    "import requests\n",
    "import fhirclient\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "#fhir server clients and configuration\n",
    "from fhirclient import client\n",
    "import fhirclient.models.patient as p\n",
    "import fhirclient.models.observation as o\n",
    "import fhirclient.models.bundle as b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "HAPI_URL = 'http://hapi.fhir.org/baseR4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure settings\n",
    "logging.basicConfig(filename=\"newfile.log\", \n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    filemode='w')\n",
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'resourceType': 'OperationOutcome', 'text': {'status': 'generated', 'div': '<div xmlns=\"http://www.w3.org/1999/xhtml\"><h1>Operation Outcome</h1><table border=\"0\"><tr><td style=\"font-weight: bold;\">ERROR</td><td>[]</td><td><pre>This is the base URL of FHIR server. Unable to handle this request, as it does not contain a resource type or operation name.</pre></td>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t</tr>\\n\\t\\t</table>\\n\\t</div>'}, 'issue': [{'severity': 'error', 'code': 'processing', 'diagnostics': 'This is the base URL of FHIR server. Unable to handle this request, as it does not contain a resource type or operation name.'}]}\n",
      "Patient Name: Dorothy Mayer\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#Test library on HAPI-FHIR test server\n",
    "resp = requests.get(HAPI_URL)\n",
    "print(resp.json())\n",
    "\n",
    "settings = {\n",
    "    'app_id': 'fhir',\n",
    "    'api_base': 'http://hapi.fhir.org/baseR4/'\n",
    "}\n",
    "\n",
    "\n",
    "#test a patient query\n",
    "SMART = client.FHIRClient(settings=settings)    \n",
    "patient = p.Patient.read('697505', SMART.server)\n",
    "p_name = SMART.human_name(patient.name[0])\n",
    "# 'Dorothy Mayer'\n",
    "print('Patient Name:', p_name)\n",
    "\n",
    "#Test sever connection\n",
    "SMART.prepare()  # prints True after fet ching CapabilityStatement"
   ]
  },
  {
   "source": [
    "## Search for observation in FHIR-SERVER\n",
    "Observation    \n",
    "85354-9: LOINC CODE, Blood pressure panel with all children optional.\n",
    "Will look for observations of blood preassure \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_observation(obs_code: str, server) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "        Recibes a code conforming to SNOMED-CT \n",
    "        e.j. http://bioportal.bioontology.org/ontologies/SNOMEDCT/?p=classes&conceptid=http%3A%2F%2Fpurl.bioontology.org%2Fontology%2FSNOMEDCT%2F38341003&jump_to_nav=true\n",
    "\n",
    "        Args:\n",
    "            obs_code [str] -- SNOMED-CT or LOINC conforming code\n",
    "            server   [   ] -- instance of fhirclient server\n",
    "        \n",
    "        Returns:\n",
    "            iatros_df [pandas.DataFrame]\n",
    "    \"\"\"\n",
    "    # Create search query\n",
    "    fs = o.Observation.where(struct = {'status':'final',\n",
    "                                    'code':{'$and': [obs_code]}\n",
    "                                        }\n",
    "                            )\n",
    "    # Perfom query to receive a Bundle resourceType since it contains pagination link.\n",
    "    bundle = fs.perform(server)\n",
    "    #print(json.dumps(bundle.as_json(), indent=2))\n",
    "    \n",
    "    # Pass bundle to handel pagination and save entries in Dataframe\n",
    "    iatros_df = handle_pagination(bundle)\n",
    "    \n",
    "    return iatros_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_pagination(bundle: fhirclient.models.bundle) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Handles a resourceType: \"Bundle\" entries, if pagination\n",
    "        link avalable iterates looking for next page entries and\n",
    "        queries the server for the next page.\n",
    "\n",
    "        Arguments:\n",
    "            bundle -- fhirclient.models.bundle\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame -- A Data frame containing inputs from\n",
    "                                 the paginated  requests.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    #Keep requesting while pagination link exists\n",
    "    while True:\n",
    "        entries = [be.resource for be in bundle.entry] if bundle is not None and bundle.entry is not None else None\n",
    "        print('Retrieved {}/{} entries...'.format(len(bundle.entry) if bundle.entry else 0, bundle.total if bundle.total else ' '))\n",
    "        \n",
    "        #Get a temp dataframe from current bundle entries\n",
    "        temp_df =  append_entries_to_dataset(bundle)\n",
    "        frames.append(temp_df)\n",
    "        #Look for a pagination link\n",
    "        if entries is not None and len(entries) > 0:\n",
    "            next_link = get_next_link_in(bundle)  \n",
    "            url_params = get_url_params(next_link)\n",
    "            if len(url_params) > 1:\n",
    "                #Query for next page\n",
    "                response = requests.get(HAPI_URL, params=url_params)\n",
    "                if response.status_code == 200:\n",
    "                    #Initialize a bundle object from request response as json\n",
    "                    try: \n",
    "                        bundle = b.Bundle(response.json())\n",
    "                    except Exception as e:\n",
    "                        print('An error ocurred while creating Bundle object')\n",
    "                        print(e)\n",
    "                        print('Error query: ', next_link)\n",
    "                        return pd.concat(frames)\n",
    "        else:\n",
    "             return pd.concat(frames)\n",
    "\n",
    "def get_url_params(url:str):\n",
    "    o = urlparse(url)\n",
    "    query = parse_qsl(o.query)\n",
    "    \n",
    "    params = dict(parse_qsl(urlsplit(url).query))\n",
    "    \n",
    "    return params\n",
    "\n",
    "def get_next_link_in(bundle):\n",
    "    if bundle.link is not None:\n",
    "        for link in bundle.link:\n",
    "            if link.relation == 'next':\n",
    "                return link.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_entries_to_dataset(bundle)-> pd.DataFrame:\n",
    "    columns = ['Patient_Ref','Dia','Sys','Units']\n",
    "    d= []\n",
    "    for entry in bundle.entry:\n",
    "        row = {}\n",
    "        resource = entry.resource\n",
    "        subject_ref = resource.subject.reference.replace('Patient/','')\n",
    "        for comp in resource.component:\n",
    "            if comp.valueQuantity is not None and comp.valueQuantity is not float('nan'):\n",
    "                bp_val = comp.valueQuantity.value\n",
    "                bp_val_unit = comp.valueQuantity.unit\n",
    "                if bp_val is not None:\n",
    "                    if comp.code.text == \"Diastolic Blood Pressure\":\n",
    "                        row['Dia'] = bp_val\n",
    "                    elif comp.code.text == \"Systolic Blood Pressure\":\n",
    "                        row['Sys'] = bp_val\n",
    "            else:\n",
    "                print('Non value quantity found')\n",
    "                continue\n",
    "            row['Units'] = bp_val_unit\n",
    "            row['Patient_Ref'] = subject_ref \n",
    "                \n",
    "        if ('Sys' in row.keys()) and ('Dia' in row.keys()):\n",
    "            sistolic = row['Sys'] \n",
    "            diastolic = row['Dia'] \n",
    "            if 130 <= sistolic <= 139 and 80 <= diastolic <= 89:\n",
    "                row['Hypertension'] = True\n",
    "            elif sistolic >= 140 and diastolic >= 90 :\n",
    "                row['Hypertension'] = True\n",
    "            else:\n",
    "                row['Hypertension'] = False  \n",
    "           \n",
    "        d.append(row)\n",
    "    \n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "source": [
    "# Run Query for observation (Blood pressure)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Non value quantity found\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Non value quantity found\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Non value quantity found\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/  entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Non value quantity found\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "Retrieved 20/2506 entries...\n",
      "An error ocurred while creating Bundle object\n",
      "{root}:\n",
      "  entry.0:\n",
      "    resource:\n",
      "      basedOn.0:\n",
      "        Superfluous entry \"fhir_comments\" in data for <fhirclient.models.fhirreference.FHIRReference object at 0x000001D8F7254B50>\n",
      "Error query:  http://hapi.fhir.org/baseR4?_getpages=1c57d70e-eebf-4e61-9efd-ce381437771f&_getpagesoffset=2320&_count=20&_pretty=true&_bundletype=searchset\n"
     ]
    }
   ],
   "source": [
    "#Reuse SMART server instance\n",
    "iatros_df = search_observation('85354-9', SMART.server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(HTML(iatros_df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean datasframe\n",
    "'''Remove nan values'''\n",
    "iatros_df = iatros_df.dropna()\n",
    "'''Reset index count and remove it'''\n",
    "iatros_df.reset_index(drop=True,inplace=True)\n",
    "#display(HTML(iatros_df.to_html()))\n",
    "iatros_df.to_csv('hypertension.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This pagination link cant be converted \n",
    "\n",
    "broken_url = 'http://hapi.fhir.org/baseR4?_getpages=300bdb01-0cdf-4349-9299-8304f540cc7c&_getpagesoffset=2320&_count=20&_pretty=true&_bundletype=searchset'\n",
    "url_params = get_url_params(broken_url)\n",
    "\n",
    "if len(url_params) > 1:\n",
    "                #Query for next page\n",
    "                response = requests.get(broken_url, params=url_params)\n",
    "                #print(response.text)\n",
    "               # print(json.dumps(response.json(), indent=2))\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    #Initialize a bundle object from request response as json\n",
    "                    try: \n",
    "                        bundle = b.Bundle(response.json())\n",
    "                    except Exception as e:\n",
    "                        print('An error ocurred while creating Bundle object')\n",
    "                        print(e)\n",
    "                        \n",
    "                "
   ]
  },
  {
   "source": [
    "## Binary classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.tabular.all import *\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dia</th>\n      <th>Sys</th>\n      <th>Hypertension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73.0</td>\n      <td>109.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>79.0</td>\n      <td>126.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>133.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76.0</td>\n      <td>136.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>111.0</td>\n      <td>172.999999</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>81.0</td>\n      <td>111.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>83.0</td>\n      <td>102.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>79.0</td>\n      <td>120.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>79.0</td>\n      <td>109.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>82.0</td>\n      <td>129.000000</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "iatros_df = pd.read_csv('hypertension.csv')\n",
    "\n",
    "try: \n",
    "    iatros_df = iatros_df.drop(columns=['Units','Patient_Ref'])\n",
    "except:\n",
    "    print('Column not in dataframe')\n",
    "    print('Available columns: ', iatros_df.columns)\n",
    "#Config Tabular DataLoader:\n",
    "cont_names = ['Dia','Sys',]\n",
    "y_name = 'Hypertension'\n",
    "procs = [Categorify, Normalize]\n",
    "dls = TabularDataLoaders.from_df(iatros_df , procs=procs,cont_names=cont_names,y_names= y_name,y_block = CategoryBlock, bs=64)\n",
    "\n",
    "splits = RandomSplitter(valid_pct= 0.2)(range_of(iatros_df))\n",
    "dls.show_batch()\n"
   ]
  },
  {
   "source": [
    "# Define model\n",
    "Will try to infer the loss function based on our y_names\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path.cwd()/'models'\n",
    "callbacks = [] \n",
    "\n",
    "if not models_path.is_dir():\n",
    "    models_path.mkdir(exist_ok=True)\n",
    " \n",
    "model_path = models_path / 'hypertension_model.pth'\n",
    "callbacks = [SaveModelCallback(every='improvement',\n",
    "                                    monitor='val_loss', \n",
    "                                    name= model_path)]\n",
    "\n",
    "learn = tabular_learner(dls, metrics=accuracy,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.702530</td>\n      <td>0.643975</td>\n      <td>0.752941</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.617202</td>\n      <td>0.512350</td>\n      <td>0.935294</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.515715</td>\n      <td>0.351538</td>\n      <td>0.961765</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.414302</td>\n      <td>0.232638</td>\n      <td>0.964706</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.325878</td>\n      <td>0.148391</td>\n      <td>0.967647</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.258103</td>\n      <td>0.102246</td>\n      <td>0.976471</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.209516</td>\n      <td>0.087636</td>\n      <td>0.958824</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.170413</td>\n      <td>0.065639</td>\n      <td>0.976471</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.138853</td>\n      <td>0.054925</td>\n      <td>0.982353</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.123613</td>\n      <td>0.050542</td>\n      <td>0.973529</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.119080</td>\n      <td>0.060216</td>\n      <td>0.970588</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.102482</td>\n      <td>0.047587</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.092383</td>\n      <td>0.042277</td>\n      <td>0.988235</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.088455</td>\n      <td>0.041026</td>\n      <td>1.000000</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.082395</td>\n      <td>0.039578</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.076412</td>\n      <td>0.036997</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.069061</td>\n      <td>0.034454</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.067545</td>\n      <td>0.030804</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.072580</td>\n      <td>0.044768</td>\n      <td>0.979412</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.075093</td>\n      <td>0.032243</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.075630</td>\n      <td>0.034424</td>\n      <td>0.991176</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.074267</td>\n      <td>0.033733</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.073430</td>\n      <td>0.036582</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.075739</td>\n      <td>0.038514</td>\n      <td>0.988235</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.070892</td>\n      <td>0.036855</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.073775</td>\n      <td>0.036558</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.070305</td>\n      <td>0.035912</td>\n      <td>0.991176</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.070946</td>\n      <td>0.033951</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.068201</td>\n      <td>0.035089</td>\n      <td>0.991176</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.067171</td>\n      <td>0.034827</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.063590</td>\n      <td>0.034051</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.064685</td>\n      <td>0.031782</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.061709</td>\n      <td>0.031461</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.067306</td>\n      <td>0.030823</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.067579</td>\n      <td>0.030116</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.065095</td>\n      <td>0.033473</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.061788</td>\n      <td>0.033552</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.063965</td>\n      <td>0.033073</td>\n      <td>0.991176</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.066738</td>\n      <td>0.033002</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.061971</td>\n      <td>0.031032</td>\n      <td>1.000000</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.058285</td>\n      <td>0.030175</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.055024</td>\n      <td>0.033055</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.058113</td>\n      <td>0.032982</td>\n      <td>0.991176</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.061351</td>\n      <td>0.030982</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.061288</td>\n      <td>0.031323</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.060271</td>\n      <td>0.030826</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.057712</td>\n      <td>0.030478</td>\n      <td>0.997059</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.062077</td>\n      <td>0.032354</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.060408</td>\n      <td>0.032514</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.060262</td>\n      <td>0.032469</td>\n      <td>0.994118</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn.fit_one_cycle(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "source": [
    "# Test predict method on a row\n",
    "\n",
    "Values can be checked on **hypertension.csv**\n",
    "\n",
    "How to select a row from file:    \n",
    "` dataframe row number  = .csv file row + 2 `\n",
    "\n",
    "- If csv file line is 2 to select this row do:    \n",
    "    `iatros_df_iloc[0]`\n",
    "        \n",
    "- ` iatros_df.iloc[20] ` will be in line 22 of .csv file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "row, clas, probs = learn.predict(iatros_df.iloc[20])\n",
    "row.show()\n",
    "print('Class: {} \\nProbabilities: {}'.format(clas,probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}